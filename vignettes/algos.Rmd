---
title: "Algorithms and Benchmarks in fastco"
author: "Drew Schmidt"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_caption: true
    toc: true
    number_sections: true
    css: include/custom.css
    highlight: kate
bibliography: include/fastco.bib
csl: "include/ieee.csl"
vignette: >
  %\VignetteIndexEntry{Algorithms and Benchmarks in fastco}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r, echo=FALSE}
library(memuse)
matmemsize <- function(n) capture.output(memuse::mu(8*2*(n+1)*n))
```


# The Algorithms with Notes on Implementation

For dense implementations, the performance should scale well, and the non-BLAS components will use multiple threads (if your compiler supports OpenMP) when the matrix has more than 2500 columns. Additionally, we try to use vector operations (using OpenMP's new `simd` construct) for additional performance; but you need a compiler that supports a relatively modern OpenMP standard for this.


## Dense Matrix Input

Given an `m`x`n` matrix `x` (input) and an `n`x`n` matrix `cos` (preallocated output):

1. Compute the upper triangle of the crossproduct `cos = t(x) %*% x` using a symmetric rank-k update (the `_syrk` BLAS function).
2. Iterate over the upper triangle of `cos`:
    1. Divide its off-diagonal values by the square root of the product of its `i`'th and `j`'th diagonal entries.
    2. Replace its diagonal values with 1.
3. Copy the upper triangle of `cos` onto its lower triangle.

The total number of floating point operations is:

1. `m*n*(n+1)` for the symmetric rank-k update.
2. `3/2*(n+1)*n` for the rescaling operation.

The algorithmic complexity is `O(mn^2)`, and is dominated by the symmetric rank-k update. The storage complexity, ignoring the required allocation of outputs (such as the `cos` matrix), is `O(1)`.


## Dense Vector-Vector Input

Given two `n`-length vectors `x` and `y` (inputs):

1. Compute `crossprod = t(x) %*% y` (using the `_gemm` BLAS function).
2. Compute the square of the Euclidean norms of `x` and `y` (using the `_syrk` BLAS function).
3. Divide `crossprod` from 1 by the square root of the product of the norms from 2.

The total number of floating point operations is:

1. `2n-1` for the crossproduct.
2. `4*n-2` for the two (square) norms.
3. `3` for the division and square root/product.

The algorithmic complexity is `O(n)`. The storage complexity is `O(1)`.


## Sparse Matrix Input

Given an `m`x`n` sparse matrix stored as a COO with row/column indices `i` and `j` **where they are sorted by columns first, then rows**, and corresponding data `a` (inputs), and given a preallocated `n`x`n` dense matrix `cos` (output):

1. Initialize `cos` to 0.
2. For each column `j` of `a` (call it `x`), find its first and final position in the COO storage.
    1. If `x` is missing (its entries are all 0), set the `j`'th row and column of the lower triangle of `cos` to `NaN` (for compatibility with dense routines).  Go to 2.
    2. Otherwise, for each column `i>j` of `a` (call it `y`), find its first and final position  in the COO storage.
    3. Compute the dot product of `x` and `y`, and call it `xy`.
    4. If `xy > epsilon` (`epsilon=1e-10` for us):
        - Compute the dot products of `x` with itself `xx` and `y` with itself `yy`.
        - Set the `(i, j)`'th entry of `cos` to `xy / sqrt(xx*yy)`.
3. Copy the lower triangle to the upper and set the diagonal to 1.

The worst case run-time complexity occurs when the matrix is dense but stored as a sparse matrix, and is `O(mn^2)`, the same as in the dense case.  However, this will cause serious cache thrashing, and the performace will be abysmal.

The function stores the `j`'th column data and its row indices in temporary storage for better cache access patterns. Best case, this requires 12 KiB of additional storage, with 8 for the data and 4 for the indices.  Worse case (an all-dense column), this balloons up to `12m`. The storage complexity is best case `O(1)`, and worst case `O(m)`.



# Benchmarks

The source code for all benchmarks presented here can be found in the source tree of this package under `inst/benchmarks/`, or in the binary installation under `benchmarks/`.

All benchmarks were performed using:

* R 3.2.2
* OpenBLAS
* gcc 5.2.1
* 4 cores of a Core i5-2500K CPU @ 3.30GHz
* Linux kernel 4.2.0-16


## Dense Matrix Input

Compared to the version in the lsa package (as of 27-Oct-2015), this implementation performs quite well:

```r
library(rbenchmark)
reps <- 100
cols <- c("test", "replications", "elapsed", "relative")

m <- 2000
n <- 200
x <- matrix(rnorm(m*n), m, n)

benchmark(fastco::cosine(x), lsa::cosine(x), columns=cols, replications=reps)

##                   test replications elapsed relative
## 1 fastco::cosine(x)          100   0.177    1.000
## 2       lsa::cosine(x)          100 113.543  641.486
```


## Dense Vector-Vector Input

Here the two perform identically:

```r
library(rbenchmark)
reps <- 100
cols <- c("test", "replications", "elapsed", "relative")

n <- 1000000
x <- rnorm(n)
y <- rnorm(n)

benchmark(fastco::cosine(x, y), lsa::cosine(x, y), columns=cols, replications=reps)

##                      test replications elapsed relative
## 1 fastco::cosine(x, y)          100   0.757    1.000
## 2       lsa::cosine(x, y)          100   0.768    1.015
```


## Sparse Matrix Input

Benchmarking sparse matrix methods can be more challenging than with dense for a variety of reasons, chief among them being that the level of sparsity can make an enormous impact in performance.

We present two cases here of varying levels of sparsity.  First, we will examine the performance for a 0.1% dense / 99.9% sparse matrix:

```r
size <- .001*m*n

dense <- generate(m, n, size)
sparse <- as.simple_triplet_matrix(dense)

memuse(dense)
## 30.518 MiB
memuse(sparse)
## 63.508 KiB

benchmark(cosine(dense), cosine(sparse), as.matrix(sparse), columns=cols, replications=reps)
##                test replications elapsed relative
## 3 as.matrix(sparse)           30   1.416    1.000
## 1     cosine(dense)           30   4.146    2.928
## 2    cosine(sparse)           30   1.770    1.250
```

The performance is quite good for the sparse case, especially considering it uses one thread while the dense one uses 4. However, as the matris becomes more dense (and it doesn't take much), dense methods begin to perform better:


```r
size <- .01*m*n

dense <- generate(m, n, size)
sparse <- as.simple_triplet_matrix(dense)

memuse(dense)
## 30.518 MiB
memuse(sparse)
## 626.008 KiB

benchmark(cosine(dense), cosine(sparse), as.matrix(sparse), columns=cols, replications=reps)
##                test replications elapsed relative
## 3 as.matrix(sparse)           30   1.370    1.000
## 1     cosine(dense)           30   4.126    3.012
## 2    cosine(sparse)           30  12.348    9.013
```

So the total time here for the dense matrix (including the cast) is about 5.5 seconds, less than half of the 12.3 seconsd for the sparse case.  However, the memory usage for the dense case is greater by a factor of 50.

It is hard to give perfect advice for when to use a dense or sparse method, but a general rule of thumb is that if you have more than 5% non-zero data, don't even bother with sparse methods unless you absolutely must for storage purposes.





# References
<script language="JavaScript" src="include/headers.js"></script>
